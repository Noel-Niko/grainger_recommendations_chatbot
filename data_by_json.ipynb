{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T14:01:41.190143Z",
     "start_time": "2024-06-26T14:01:41.185289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "domain = \"https://www.grainger.com\"\n",
    "local_domain = urlparse(domain).netloc\n",
    "# Create necessary directories if they don't exist\n",
    "if not os.path.exists(\"text/\"):\n",
    "    os.mkdir(\"text/\")\n",
    "if not os.path.exists(f\"text/{local_domain}/\"):\n",
    "    os.mkdir(f\"text/{local_domain}/\")\n",
    "if not os.path.exists(\"processed\"):\n",
    "    os.mkdir(\"processed\")"
   ],
   "id": "2a11e5f910934738",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T14:01:41.985629Z",
     "start_time": "2024-06-26T14:01:41.191863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "# List of part numbers to query\n",
    "part_number = \"1VCE8\"  # Add more part numbers as needed\n",
    "\n",
    "# Base URL for the endpoint\n",
    "base_url = \"https://mobile-rest-qa.nonprod.graingercloud.com/v1/product/detail\"\n",
    "\n",
    "# File to store the results\n",
    "file_path = f\"text/{local_domain}/{part_number}.txt\"\n",
    "\n",
    "# Headers for the request\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Function to fetch and process data\n",
    "def fetch_product_details(part_number):\n",
    "    params = {\n",
    "        \"partNumbers\": part_number,\n",
    "        \"extraInfo\": \"false\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(base_url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()[0]  # Assuming the response contains a list with one item\n",
    "\n",
    "        brand = data.get(\"brand\", {}).get(\"name\", \"N/A\")\n",
    "        code = data.get(\"code\", \"N/A\")\n",
    "        name = data.get(\"name\", \"N/A\")\n",
    "        picture_url = data.get(\"pictureUrl600\", \"N/A\")\n",
    "        price = data.get(\"priceData\", {}).get(\"formattedPrice\", \"N/A\")\n",
    "        description = data.get(\"productDetailsDescription\", \"N/A\")\n",
    "\n",
    "        return {\n",
    "            \"Brand\": brand,\n",
    "            \"Code\": code,\n",
    "            \"Name\": name,\n",
    "            \"PictureUrl600\": picture_url,\n",
    "            \"Price\": price,\n",
    "            \"Description\": description\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Fetch details for each part number and write to file\n",
    "with open(file_path, \"w\") as file:\n",
    "    details = fetch_product_details(part_number)\n",
    "    if details:           \n",
    "        # file.write(json.dumps(details) + \"\\n\")\n",
    "        print(details)\n",
    "    else:\n",
    "        file.write(f\"Failed to fetch details for part number: {part_number}\\n\")\n",
    "\n",
    "print(\"Product details have been written to\", file_path)\n"
   ],
   "id": "1c52c147b6202dca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Brand': 'DAYTON', 'Code': '1VCE8', 'Name': 'DAYTON Standard-Duty Industrial Fan: 24 in Blade Dia, 2 Speeds, 3,850/6,200 cfm, 115 V AC', 'PictureUrl600': 'https://static.grainger.com/rp/s/is/image/Grainger/1VCF3_AS02?$lgmain$', 'Price': '$474.08', 'Description': '<p>Standard-duty industrial fan heads provide cooling in heavy manufacturing areas and other dusty or dirty environments. These fan blade, motor, and guard assemblies can be paired with a new or existing bracket or base.</p>'}\n",
      "Product details have been written to text/www.grainger.com/1VCE8.txt\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T14:01:41.988839Z",
     "start_time": "2024-06-26T14:01:41.986386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "# Pattern to match product skus/codes\n",
    "regex_pattern = re.compile(r'[A-Z0-9]{5,7}')\n",
    "# Test strings\n",
    "test_strings = [\n",
    "    \"1DKW3_1.pdf\",\n",
    "    \"3VE59C-Operating-Instructions-and-Parts-Manual.pdf\",\n",
    "    \"_3M-Disposable-Respirator-Dual-4JF99?opr=PDPBRDSP&analytics=dsbrItems_5ZZZ6.txt\"\n",
    "]\n",
    "\n",
    "# Extract product codes from test strings\n",
    "for test in test_strings:\n",
    "    matches = regex_pattern.findall(test)\n",
    "    print(f\"Matches in '{test}': {matches}\")\n"
   ],
   "id": "a61fd1fe2b624523",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches in '1DKW3_1.pdf': ['1DKW3']\n",
      "Matches in '3VE59C-Operating-Instructions-and-Parts-Manual.pdf': ['3VE59C']\n",
      "Matches in '_3M-Disposable-Respirator-Dual-4JF99?opr=PDPBRDSP&analytics=dsbrItems_5ZZZ6.txt': ['4JF99', 'PDPBRDS', '5ZZZ6']\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T14:01:42.816356Z",
     "start_time": "2024-06-26T14:01:41.990122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Define the regex pattern for product codes\n",
    "regex_pattern = re.compile(r'[A-Z0-9]{5,7}')\n",
    "\n",
    "# Directory containing the files\n",
    "directory = 'GraingerWebScrape/www.grainger.com'\n",
    "\n",
    "# List to store found product codes\n",
    "product_codes = []\n",
    "\n",
    "# Function to extract product codes from text\n",
    "def extract_product_codes(text):\n",
    "    return regex_pattern.findall(text)\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "\n",
    "        # Check for product codes in the file name\n",
    "        codes_in_filename = extract_product_codes(file)\n",
    "        product_codes.extend(codes_in_filename)\n",
    "\n",
    "        # Check for product codes in the file content\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                codes_in_content = extract_product_codes(content)\n",
    "                product_codes.extend(codes_in_content)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read file {file_path}: {e}\")\n",
    "\n",
    "# Remove duplicates by converting the list to a set and back to a list\n",
    "product_codes = list(set(product_codes))\n",
    "\n",
    "# Save all product codes to a single JSON file\n",
    "with open('all_product_codes.json', 'w') as f:\n",
    "    json.dump(product_codes, f, indent=4)\n",
    "\n",
    "print(f\"Total product codes found: {len(product_codes)}\")\n",
    "print(f\"Product codes saved in 'all_product_codes.json'\")\n"
   ],
   "id": "1d225d8e17be55ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not read file GraingerWebScrape/www.grainger.com/1DKW3_2.pdf: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Could not read file GraingerWebScrape/www.grainger.com/4NHG9_1.pdf: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Could not read file GraingerWebScrape/www.grainger.com/1DKW3_3.pdf: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Could not read file GraingerWebScrape/www.grainger.com/1DKW3_1.pdf: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Could not read file GraingerWebScrape/www.grainger.com/4NHG9_2.pdf: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Could not read file GraingerWebScrape/www.grainger.com/TraumaCube__XE7K_v1.pdf: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Could not read file GraingerWebScrape/www.grainger.com/1106-1600_PI_en_US1__JQ1I.pdf: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Could not read file GraingerWebScrape/www.grainger.com/3VE59C-Operating-Instructions-and-Parts-Manual.pdf: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Could not read file GraingerWebScrape/www.grainger.com/QMARK-Radiant-Desk-Heater-Installation-Instructions.pdf: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Could not read file GraingerWebScrape/www.grainger.com/3PEA8_1.pdf: 'utf-8' codec can't decode byte 0xc7 in position 10: invalid continuation byte\n",
      "Could not read file GraingerWebScrape/www.grainger.com/53TY91_1.pdf: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Could not read file GraingerWebScrape/www.grainger.com/55KH88Manual__LFV2_v1.pdf: 'utf-8' codec can't decode byte 0xa1 in position 11: invalid start byte\n",
      "Could not read file GraingerWebScrape/www.grainger.com/2MY17_1.pdf: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Could not read file GraingerWebScrape/www.grainger.com/53TY90_1.pdf: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Total product codes found: 9651\n",
      "Product codes saved in 'all_product_codes.json'\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T14:01:42.820514Z",
     "start_time": "2024-06-26T14:01:42.817239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Base URL and headers for the API\n",
    "base_url = \"https://mobile-rest-qa.nonprod.graingercloud.com/v1/product/detail\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Function to fetch and process data\n",
    "def fetch_product_details(skus):\n",
    "    params = {\n",
    "        \"partNumbers\": skus,\n",
    "        \"extraInfo\": \"false\"\n",
    "    }\n",
    "    response = requests.get(base_url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()[0]  # Assuming the response contains a list with one item\n",
    "        brand = data.get(\"brand\", {}).get(\"name\", \"N/A\")\n",
    "        code = data.get(\"code\", \"N/A\")\n",
    "        name = data.get(\"name\", \"N/A\")\n",
    "        picture_url = data.get(\"pictureUrl600\", \"N/A\")\n",
    "        price = data.get(\"priceData\", {}).get(\"formattedPrice\", \"N/A\")\n",
    "        description = data.get(\"productDetailsDescription\", \"N/A\")\n",
    "\n",
    "        return {\n",
    "            \"Brand\": brand,\n",
    "            \"Code\": code,\n",
    "            \"Name\": name,\n",
    "            \"PictureUrl600\": picture_url,\n",
    "            \"Price\": price,\n",
    "            \"Description\": description\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# \n",
    "# # DataFrame to store product details\n",
    "# df = pd.DataFrame(columns=[\"Brand\", \"Code\", \"Name\", \"PictureUrl600\", \"Price\", \"Description\"])\n",
    "\n",
    "# Fetch details for each part number and append to DataFrame\n",
    "# for part_number in part_numbers:\n",
    "#     details = fetch_product_details(part_number)\n",
    "#     if details:\n",
    "#         df = pd.concat([df, pd.DataFrame([details])], ignore_index=True)\n",
    "#     else:\n",
    "#         print(f\"Failed to fetch details for part number: {part_number}\")\n",
    "\n",
    "# Save DataFrame to a Parquet file\n",
    "# df.to_parquet('processed/grainger_products.parquet', index=False)\n",
    "# \n",
    "# \n",
    "# print(\"Product details have been saved to 'processed/grainger_products.parquet'\")\n",
    "# \n",
    "# print(df.head())\n",
    "# print(df.tail())\n",
    "# print(df.size)\n",
    "# print(df.values)\n"
   ],
   "id": "b77bc953998ebdfd",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T14:08:24.540961Z",
     "start_time": "2024-06-26T14:08:23.909068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Load the product codes from the JSON file\n",
    "with open('all_product_codes.json', 'r') as f:\n",
    "    product_codes = [\"1VCE8\", \"2KNK4\", \"20HC15\"]\n",
    "       #json.load(f)\n",
    "\n",
    "# Product codes in chunks of 100\n",
    "chunk_size = 100\n",
    "chunks = [product_codes[i:i + chunk_size] for i in range(0, len(product_codes), chunk_size)]\n",
    "\n",
    "# Iterate over each chunk for API requests\n",
    "df = pd.DataFrame(columns=[\"Brand\", \"Code\", \"Name\", \"PictureUrl600\", \"Price\", \"Description\"])\n",
    "for chunk in chunks:\n",
    "    try:\n",
    "        details = fetch_product_details(chunk)\n",
    "        df = pd.concat([df, pd.DataFrame([details])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch details for chunk: {chunk}\")\n",
    "\n",
    "print(\"All product details have been processed.\")\n",
    "# Remove rows where all columns are NaN\n",
    "df = df.dropna(how='all')\n",
    "# Ensure all column names are strings\n",
    "df.columns = df.columns.astype(str)\n",
    "# Save to Parquet\n",
    "df.to_parquet('processed/grainger_products.parquet', index=False)\n",
    "print(\"Product details have been saved to 'processed/grainger_products.parquet'\")\n",
    "print(\"\\nHead of DataFrame:\")\n",
    "print(df.head(), \"\\n\")\n",
    "print(\"Tail of DataFrame:\")\n",
    "print(df.tail(), \"\\n\")\n",
    "print(\"Size of DataFrame:\", df.size, \"\\n\")\n",
    "print(\"Values in DataFrame:\")\n",
    "print(df.values)\n",
    "\n"
   ],
   "id": "2be7d8d11bdb58fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All product details have been processed.\n",
      "Product details have been saved to 'processed/grainger_products.parquet'\n",
      "\n",
      "Head of DataFrame:\n",
      "  Brand    Code                        Name  \\\n",
      "0   CRC  20HC15  Window and Display Cleaner   \n",
      "\n",
      "                                       PictureUrl600   Price Description  \n",
      "0  https://static.grainger.com/rp/s/is/image/Grai...  $10.20        None   \n",
      "\n",
      "Tail of DataFrame:\n",
      "  Brand    Code                        Name  \\\n",
      "0   CRC  20HC15  Window and Display Cleaner   \n",
      "\n",
      "                                       PictureUrl600   Price Description  \n",
      "0  https://static.grainger.com/rp/s/is/image/Grai...  $10.20        None   \n",
      "\n",
      "Size of DataFrame: 6 \n",
      "\n",
      "Values in DataFrame:\n",
      "[['CRC' '20HC15' 'Window and Display Cleaner'\n",
      "  'https://static.grainger.com/rp/s/is/image/Grainger/20HC15_AS01?$lgmain$'\n",
      "  '$10.20' None]]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-26T14:12:19.492754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import requests\n",
    "# import pandas as pd\n",
    "# import json\n",
    "# \n",
    "# # Base URL and headers for the API\n",
    "# base_url = \"https://mobile-rest-qa.nonprod.graingercloud.com/v1/product/detail\"\n",
    "# headers = {\n",
    "#     \"Content-Type\": \"application/json\"\n",
    "# }\n",
    "# \n",
    "# # Function to fetch and process data\n",
    "# def fetch_product_details(skus):\n",
    "#     params = {\n",
    "#         \"partNumbers\": skus,\n",
    "#         \"extraInfo\": \"false\"\n",
    "#     }\n",
    "#     response = requests.get(base_url, headers=headers, params=params)\n",
    "#     if response.status_code == 200:\n",
    "#         try:\n",
    "#             data = response.json()\n",
    "#             results = []\n",
    "#             for item in data:\n",
    "#                 brand = item.get(\"brand\", {}).get(\"name\", \"N/A\")\n",
    "#                 code = item.get(\"code\", \"N/A\")\n",
    "#                 name = item.get(\"name\", \"N/A\")\n",
    "#                 picture_url = item.get(\"pictureUrl600\", \"N/A\")\n",
    "#                 price = item.get(\"priceData\", {}).get(\"formattedPrice\", \"N/A\")\n",
    "#                 description = item.get(\"productDetailsDescription\", \"N/A\")\n",
    "#                 \n",
    "#                 results.append({\n",
    "#                     \"Brand\": brand,\n",
    "#                     \"Code\": code,\n",
    "#                     \"Name\": name,\n",
    "#                     \"PictureUrl600\": picture_url,\n",
    "#                     \"Price\": price,\n",
    "#                     \"Description\": description\n",
    "#                 })\n",
    "#                 \n",
    "#             return pd.DataFrame(results) if results else None\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error parsing response for {skus}: {e}\")\n",
    "#             return None\n",
    "#     else:\n",
    "#         print(f\"Failed to fetch details for {skus}: Status code {response.status_code}\")\n",
    "#         return None\n",
    "# \n",
    "# # Load the product codes from the JSON file\n",
    "# with open('all_product_codes.json', 'r') as f:\n",
    "#     product_codes = json.load(f)\n",
    "# \n",
    "# # For testing, use a smaller subset of product codes\n",
    "# # product_codes = [\"1VCE8\", \"2KNK4\", \"20HC15\"]\n",
    "# \n",
    "# # Product codes in chunks of 100\n",
    "# chunk_size = 1\n",
    "# chunks = [product_codes[i:i + chunk_size] for i in range(0, len(product_codes), chunk_size)]\n",
    "# \n",
    "# # Iterate over each chunk for API requests\n",
    "# df = pd.DataFrame(columns=[\"Brand\", \"Code\", \"Name\", \"PictureUrl600\", \"Price\", \"Description\"])\n",
    "# for chunk in chunks:\n",
    "#     try:\n",
    "#         details = fetch_product_details(chunk)\n",
    "#         if details is not None:\n",
    "#             df = pd.concat([df, details], ignore_index=True)\n",
    "#         else:\n",
    "#             print(f\"No details fetched for chunk: {chunk}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to fetch details for chunk: {chunk}, Error: {e}\")\n",
    "# \n",
    "# print(\"All product details have been processed.\")\n",
    "# \n",
    "# # Remove rows where all columns are NaN\n",
    "# df = df.dropna(how='all')\n",
    "# \n",
    "# # Ensure all column names are strings\n",
    "# df.columns = df.columns.astype(str)\n",
    "# \n",
    "# # Save to Parquet\n",
    "# df.to_parquet('processed/grainger_products.parquet', index=False)\n",
    "# print(\"Product details have been saved to 'processed/grainger_products.parquet'\")\n",
    "# print(\"\\nHead of DataFrame:\")\n",
    "# print(df.head(), \"\\n\")\n",
    "# print(\"Tail of DataFrame:\")\n",
    "# print(df.tail(), \"\\n\")\n",
    "# print(\"Size of DataFrame:\", df.size, \"\\n\")\n",
    "# print(\"Values in DataFrame:\")\n",
    "# print(df.values)\n"
   ],
   "id": "659508ee1bd0dd44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch details for ['182UFW9']: Status code 400\n",
      "No details fetched for chunk: ['182UFW9']\n",
      "Failed to fetch details for ['04103']: Status code 400\n",
      "No details fetched for chunk: ['04103']\n",
      "Failed to fetch details for ['97429T7']: Status code 400\n",
      "No details fetched for chunk: ['97429T7']\n",
      "Failed to fetch details for ['ZEREXH']: Status code 400\n",
      "No details fetched for chunk: ['ZEREXH']\n",
      "Failed to fetch details for ['ICHELIN']: Status code 400\n",
      "No details fetched for chunk: ['ICHELIN']\n",
      "Failed to fetch details for ['6391H']: Status code 400\n",
      "No details fetched for chunk: ['6391H']\n",
      "Failed to fetch details for ['00818HC']: Status code 400\n",
      "No details fetched for chunk: ['00818HC']\n",
      "Failed to fetch details for ['40R19']: Status code 400\n",
      "No details fetched for chunk: ['40R19']\n",
      "Failed to fetch details for ['ALTERNA']: Status code 400\n",
      "No details fetched for chunk: ['ALTERNA']\n",
      "Failed to fetch details for ['FOOTWEA']: Status code 400\n",
      "No details fetched for chunk: ['FOOTWEA']\n",
      "Failed to fetch details for ['0846C11']: Status code 400\n",
      "No details fetched for chunk: ['0846C11']\n",
      "Failed to fetch details for ['MERET']: Status code 400\n",
      "No details fetched for chunk: ['MERET']\n",
      "Failed to fetch details for ['2L18018']: Status code 400\n",
      "No details fetched for chunk: ['2L18018']\n",
      "Failed to fetch details for ['2813X77']: Status code 400\n",
      "No details fetched for chunk: ['2813X77']\n",
      "Failed to fetch details for ['10031DL']: Status code 400\n",
      "No details fetched for chunk: ['10031DL']\n",
      "Failed to fetch details for ['341UKH6']: Status code 400\n",
      "No details fetched for chunk: ['341UKH6']\n",
      "Failed to fetch details for ['4C13794']: Status code 400\n",
      "No details fetched for chunk: ['4C13794']\n",
      "Failed to fetch details for ['504YPD1']: Status code 400\n",
      "No details fetched for chunk: ['504YPD1']\n",
      "Failed to fetch details for ['EM7252E']: Status code 400\n",
      "No details fetched for chunk: ['EM7252E']\n",
      "Failed to fetch details for ['40KJ09C']: Status code 400\n",
      "No details fetched for chunk: ['40KJ09C']\n",
      "Failed to fetch details for ['9WX7043']: Status code 400\n",
      "No details fetched for chunk: ['9WX7043']\n",
      "Failed to fetch details for ['90670']: Status code 400\n",
      "No details fetched for chunk: ['90670']\n",
      "Failed to fetch details for ['0515F21']: Status code 400\n",
      "No details fetched for chunk: ['0515F21']\n",
      "Failed to fetch details for ['65R17']: Status code 400\n",
      "No details fetched for chunk: ['65R17']\n",
      "Failed to fetch details for ['274GB90']: Status code 400\n",
      "No details fetched for chunk: ['274GB90']\n",
      "Failed to fetch details for ['OVERINE']: Status code 400\n",
      "No details fetched for chunk: ['OVERINE']\n",
      "Failed to fetch details for ['TC02C']: Status code 400\n",
      "No details fetched for chunk: ['TC02C']\n",
      "Failed to fetch details for ['173MUE5']: Status code 400\n",
      "No details fetched for chunk: ['173MUE5']\n",
      "Failed to fetch details for ['8553WN5']: Status code 400\n",
      "No details fetched for chunk: ['8553WN5']\n",
      "Failed to fetch details for ['2REEBOK']: Status code 400\n",
      "No details fetched for chunk: ['2REEBOK']\n",
      "Failed to fetch details for ['992TGC7']: Status code 400\n",
      "No details fetched for chunk: ['992TGC7']\n",
      "Failed to fetch details for ['8G843']: Status code 500\n",
      "No details fetched for chunk: ['8G843']\n",
      "Failed to fetch details for ['116765']: Status code 400\n",
      "No details fetched for chunk: ['116765']\n",
      "Failed to fetch details for ['817F52']: Status code 400\n",
      "No details fetched for chunk: ['817F52']\n",
      "Failed to fetch details for ['116207']: Status code 400\n",
      "No details fetched for chunk: ['116207']\n",
      "Failed to fetch details for ['39R839L']: Status code 400\n",
      "No details fetched for chunk: ['39R839L']\n",
      "Failed to fetch details for ['P89135W']: Status code 400\n",
      "No details fetched for chunk: ['P89135W']\n",
      "Failed to fetch details for ['WOOSTER']: Status code 400\n",
      "No details fetched for chunk: ['WOOSTER']\n",
      "Failed to fetch details for ['P90439D']: Status code 400\n",
      "No details fetched for chunk: ['P90439D']\n",
      "Failed to fetch details for ['846KEC3']: Status code 400\n",
      "No details fetched for chunk: ['846KEC3']\n",
      "Failed to fetch details for ['FS2650C']: Status code 400\n",
      "No details fetched for chunk: ['FS2650C']\n",
      "Failed to fetch details for ['1029XM5']: Status code 400\n",
      "No details fetched for chunk: ['1029XM5']\n",
      "Failed to fetch details for ['VA225']: Status code 400\n",
      "No details fetched for chunk: ['VA225']\n",
      "Failed to fetch details for ['86515TI']: Status code 400\n",
      "No details fetched for chunk: ['86515TI']\n",
      "Failed to fetch details for ['3A1F297']: Status code 400\n",
      "No details fetched for chunk: ['3A1F297']\n",
      "Failed to fetch details for ['ASSISTA']: Status code 400\n",
      "No details fetched for chunk: ['ASSISTA']\n",
      "Failed to fetch details for ['RB4310K']: Status code 400\n",
      "No details fetched for chunk: ['RB4310K']\n",
      "Failed to fetch details for ['92641KE']: Status code 400\n",
      "No details fetched for chunk: ['92641KE']\n",
      "Failed to fetch details for ['53531AR']: Status code 400\n",
      "No details fetched for chunk: ['53531AR']\n",
      "Failed to fetch details for ['43A5954']: Status code 400\n",
      "No details fetched for chunk: ['43A5954']\n",
      "Failed to fetch details for ['543A706']: Status code 400\n",
      "No details fetched for chunk: ['543A706']\n",
      "Failed to fetch details for ['246KEA0']: Status code 400\n",
      "No details fetched for chunk: ['246KEA0']\n",
      "Failed to fetch details for ['1652WH3']: Status code 400\n",
      "No details fetched for chunk: ['1652WH3']\n",
      "Failed to fetch details for ['46256']: Status code 400\n",
      "No details fetched for chunk: ['46256']\n",
      "Failed to fetch details for ['404K74M']: Status code 400\n",
      "No details fetched for chunk: ['404K74M']\n",
      "Failed to fetch details for ['FUNCTIO']: Status code 400\n",
      "No details fetched for chunk: ['FUNCTIO']\n",
      "Failed to fetch details for ['49430']: Status code 400\n",
      "No details fetched for chunk: ['49430']\n",
      "Failed to fetch details for ['955EC12']: Status code 400\n",
      "No details fetched for chunk: ['955EC12']\n",
      "Failed to fetch details for ['355JK37']: Status code 400\n",
      "No details fetched for chunk: ['355JK37']\n",
      "Failed to fetch details for ['985RXG3']: Status code 400\n",
      "No details fetched for chunk: ['985RXG3']\n",
      "Failed to fetch details for ['43C0314']: Status code 400\n",
      "No details fetched for chunk: ['43C0314']\n",
      "Failed to fetch details for ['6804AZ5']: Status code 400\n",
      "No details fetched for chunk: ['6804AZ5']\n",
      "Failed to fetch details for ['IP54I']: Status code 400\n",
      "No details fetched for chunk: ['IP54I']\n",
      "Failed to fetch details for ['8044208']: Status code 400\n",
      "No details fetched for chunk: ['8044208']\n",
      "Failed to fetch details for ['30R20']: Status code 400\n",
      "No details fetched for chunk: ['30R20']\n",
      "Failed to fetch details for ['6638M50']: Status code 400\n",
      "No details fetched for chunk: ['6638M50']\n",
      "Failed to fetch details for ['91712M']: Status code 400\n",
      "No details fetched for chunk: ['91712M']\n",
      "Failed to fetch details for ['1505BB5']: Status code 400\n",
      "No details fetched for chunk: ['1505BB5']\n",
      "Failed to fetch details for ['43A6034']: Status code 400\n",
      "No details fetched for chunk: ['43A6034']\n",
      "Failed to fetch details for ['77055W']: Status code 400\n",
      "No details fetched for chunk: ['77055W']\n",
      "Failed to fetch details for ['EHSLP']: Status code 400\n",
      "No details fetched for chunk: ['EHSLP']\n",
      "Failed to fetch details for ['83JY32S']: Status code 400\n",
      "No details fetched for chunk: ['83JY32S']\n",
      "Failed to fetch details for ['SQWINCH']: Status code 400\n",
      "No details fetched for chunk: ['SQWINCH']\n",
      "Failed to fetch details for ['U53490U']: Status code 400\n",
      "No details fetched for chunk: ['U53490U']\n",
      "Failed to fetch details for ['LOCKOUT']: Status code 400\n",
      "No details fetched for chunk: ['LOCKOUT']\n",
      "Failed to fetch details for ['JOHNSON']: Status code 400\n",
      "No details fetched for chunk: ['JOHNSON']\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a23af246e9826876"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
