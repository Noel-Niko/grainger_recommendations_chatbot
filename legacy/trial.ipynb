{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-04T04:36:41.771378Z",
     "start_time": "2024-07-04T04:36:41.751833Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "parquet_file_directory = \"processed\"\n",
    "parquet_file_path = os.path.join(parquet_file_directory, \"grainger_products.parquet\")\n",
    "\n",
    "    # \"modules/vector_index/processed/grainger_products.parquet\"\n",
    "\n",
    "print(\"Attempting to load file from:\", parquet_file_path)\n",
    "\n",
    "# Now attempt to load the file\n",
    "try:\n",
    "    df = pd.read_parquet(parquet_file_path)\n",
    "    print(\"File loaded successfully!\")\n",
    "except FileNotFoundError as e:\n",
    "    print(\"Error loading file:\", e)\n",
    "\n",
    "print(df.head())"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "e80856e5ef5a5f8b",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T04:38:15.090602Z",
     "start_time": "2024-07-04T04:38:15.058009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import S3FileLoader\n",
    "from bedrock_initializer import LLMInitializer\n",
    "from data_frame_initializer import DataFrameSingleton\n",
    "# from .bedrock_initializer import LLMInitializer\n",
    "# from .data_frame_initializer import DataFrameSingleton\n",
    "\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "def log_creation_time(file_path):\n",
    "    ctime = os.path.getctime(file_path)\n",
    "    creation_time = datetime.fromtimestamp(ctime).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    logging.info(f\"File '{file_path}' was created on {creation_time}\")\n",
    "\n",
    "\n",
    "class Document:\n",
    "    _instance = None\n",
    "    _vector_index = None\n",
    "    _df = None\n",
    "    _llm = None\n",
    "    _bedrock_embeddings = None\n",
    "\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(Document, cls).__new__(cls)\n",
    "        return cls._instance\n",
    "\n",
    "    def __init__(self, page_content, metadata):\n",
    "        self.page_content = page_content\n",
    "        self.metadata = metadata\n",
    "\n",
    "    @classmethod\n",
    "    def get_instance(cls, **kwargs):\n",
    "        \"\"\"Static access method to get the singleton instance, enforcing required arguments.\"\"\"\n",
    "        logging.info(\"Entering get_instance method\")\n",
    "\n",
    "        if cls._vector_index is None or cls._df is None:\n",
    "            cls._llm = cls.initialize_llm()\n",
    "            cls._bedrock_embeddings = cls.initialize_bedrock()\n",
    "            documents = []\n",
    "            # data_frame_singleton = DataFrameSingleton.get_instance()\n",
    "            df.head()\n",
    "            cls._df = df\n",
    "\n",
    "            logging.info(f\"DataFrame contains {cls._df.shape[0]} rows\")\n",
    "\n",
    "            for idx, (_, row) in enumerate(cls._df.iterrows()):\n",
    "                logging.info(f\"Processing row {idx + 1}/{cls._df.shape[0]} with code: {row['Code']}\")\n",
    "                page_content = f\"{row['Code']} {row['Name']} {row['Brand']} {row['Description'] if pd.notna(row['Description']) else ''}\"\n",
    "                metadata = {\n",
    "                    'Brand': row['Brand'],\n",
    "                    'Code': row['Code'],\n",
    "                    'Name': row['Name'],\n",
    "                    'Description': row['Description'],\n",
    "                    'Price': row['Price']\n",
    "                }\n",
    "\n",
    "                logging.debug(f\"Page content for document {idx + 1}: {page_content}\")\n",
    "                logging.debug(f\"Metadata for document {idx + 1}: {metadata}\")\n",
    "\n",
    "                # Check if the document is unique before appending\n",
    "                if not any(doc.page_content == page_content for doc in documents):\n",
    "                    documents.append(Document(page_content, metadata))\n",
    "                else:\n",
    "                    logging.warning(f\"Duplicate document found for code: {row['Code']}\")\n",
    "\n",
    "            # Print the structured documents\n",
    "            logging.info(\"Structured documents created:\")\n",
    "            for idx, doc in enumerate(documents[:5], 1):\n",
    "                logging.info(f\"Document {idx} of {len(documents)}:\")\n",
    "                logging.info(doc.page_content[:200])\n",
    "\n",
    "            # Create FAISS vector store from structured documents\n",
    "            logging.info(\"Creating FAISS vector store from structured documents...:\", documents.pop().page_content[:200])\n",
    "            start_time = time.time()\n",
    "            cls._vector_index = FAISS.from_documents(documents=documents, embedding=cls._bedrock_embeddings)\n",
    "            end_time = time.time()\n",
    "            time_taken = end_time - start_time\n",
    "            logging.info(f\"Created FAISS vector store from structured documents in {time_taken} seconds.\")\n",
    "\n",
    "        return cls._vector_index, cls._llm, cls._bedrock_embeddings, cls._df\n",
    "\n",
    "    @classmethod\n",
    "    def recreate_index(cls, **kwargs):\n",
    "        \"\"\"Method to force the recreation of the vector index.\"\"\"\n",
    "        logging.info(\"Entering recreate_index method\")\n",
    "        cls._vector_index = None\n",
    "        return cls.get_instance(**kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def initialize_llm(cls):\n",
    "        logging.info(\"Setting up LLM\")\n",
    "        llm_initializer = LLMInitializer()\n",
    "        llm, bedrock_runtime = llm_initializer.check_and_initialize_llm()\n",
    "        if llm is None:\n",
    "            logging.warning(\"Failed to initialize LLM\")\n",
    "            raise ValueError(\"Failed to initialize LLM\")\n",
    "        cls._llm = llm\n",
    "        cls._bedrock_runtime = bedrock_runtime\n",
    "        logging.info(\"LLM initialized\")\n",
    "        return cls._llm\n",
    "\n",
    "    @classmethod\n",
    "    def initialize_bedrock(cls):\n",
    "        logging.info(\"Initializing Titan Embeddings Model...\")\n",
    "        bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\", client=cls._bedrock_runtime)\n",
    "        logging.info(\"Titan Embeddings Model initialized.\")\n",
    "        return bedrock_embeddings\n"
   ],
   "id": "8341e6788b21d65f",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T04:44:21.223260Z",
     "start_time": "2024-07-04T04:38:19.217234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "document, llm, bedrock_embeddings, df = Document.get_instance()\n",
    "print(\"Here\")"
   ],
   "id": "27507320ef570f48",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T04:32:08.724031Z",
     "start_time": "2024-07-04T04:32:08.718313Z"
    }
   },
   "cell_type": "code",
   "source": "customer_input = \"I am looking for waterproof insulated boots for my men working on my commercial deep sea fishing boat in the arctic. Must have large sizes.\"",
   "id": "4ab4a978586ebfff",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T04:32:22.965829Z",
     "start_time": "2024-07-04T04:32:12.326767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## GET LIST OF PRODUCTS AND CODES\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template2 = \"\"\"Human: Extract list of 5 products and their respective physical IDs from catalog that matches the style given below. \n",
    "The catalog of products is provided under <catalog></catalog> tags below.\n",
    "<catalog>\n",
    "{context}\n",
    "</catalog>\n",
    "Style: {question}\n",
    "\n",
    "The output should be a json of the form <products>[{{\"product\": <description of the product from the catalog>, \"code\":<code of the product from the catalog>}}, ...]</products>\n",
    "Skip the preamble and always return valid json.\n",
    "Assistant: \"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template2, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# Use RetrievalQA customizations for improving Q&A experience\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=document.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": 6}\n",
    "    ),\n",
    "    return_source_documents=False,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    ")\n",
    "\n",
    "recs_response = qa({\"query\": customer_input})['result']\n",
    "recs_response"
   ],
   "id": "fb78b3c08d818c7",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T18:44:36.169460Z",
     "start_time": "2024-07-04T18:44:36.160883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import html\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'Code': ['1VCE8 ALTERNATIVE VENDOR', '2BZL6 PRIMARY VENDOR', '3CDE9 OTHER VENDOR']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def clean_code(code):\n",
    "    # Extract the part before any space or other characters\n",
    "    return re.split(r'\\s|[-_()]+', code, 1)[0]\n",
    "\n",
    "# Apply clean_code to 'Code' column\n",
    "df['Code'] = df['Code'].apply(clean_code)\n",
    "\n",
    "# Remove HTML characters from all columns (if any)\n",
    "df = df.applymap(lambda x: html.unescape(x) if isinstance(x, str) else x)\n",
    "\n",
    "print(df)\n"
   ],
   "id": "db100075b517c276",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "b2333072ba61daaf",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
