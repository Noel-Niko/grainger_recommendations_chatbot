{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T04:00:30.719850Z",
     "start_time": "2024-06-24T04:00:17.303487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Selenium setup\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "def search_product(product_id):\n",
    "    # Search URL for the product\n",
    "    search_url = f'https://www.zoro.com/search?q={product_id}'\n",
    "    driver.get(search_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "    # Get the page source after it loads\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Find the specific product link using a precise CSS selector\n",
    "    product_link = None\n",
    "    for a in soup.select('a.product-card-image__link'):\n",
    "        if product_id.lower() in a['href'].lower():\n",
    "            product_link = urljoin(search_url, a['href'])\n",
    "            break\n",
    "\n",
    "    if product_link:\n",
    "        print(f\"Found product URL: {product_link}\")\n",
    "    else:\n",
    "        print(\"Product URL not found.\")\n",
    "\n",
    "    return product_link\n",
    "\n",
    "product_id = '1VCE9'\n",
    "product_url = search_product(product_id)\n",
    "\n",
    "driver.quit()\n"
   ],
   "id": "7814770bc1fce0cd",
   "execution_count": 44,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T03:35:49.859475Z",
     "start_time": "2024-06-24T03:35:38.211399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "def extract_reviews(html_content):\n",
    "    if not html_content:\n",
    "        print(\"No HTML content to process.\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Extracting star rating\n",
    "    star_rating_container = soup.find('section', class_='pr-review-snapshot-block-snippet')\n",
    "    if star_rating_container:\n",
    "        star_rating = star_rating_container.find('div', class_='pr-snippet-stars')\n",
    "        star_rating_text = star_rating_container.find('div', class_='pr-snippet-rating-decimal').text.strip()\n",
    "        if star_rating:\n",
    "            star_rating_label = star_rating['aria-label']\n",
    "            print(f\"Star Rating: {star_rating_label}, {star_rating_text}\")\n",
    "        else:\n",
    "            print(\"Star Rating not found.\")\n",
    "    else:\n",
    "        print(\"Star Rating container not found.\")\n",
    "\n",
    "    # Extracting recommendation percentage\n",
    "    recommendation_section = soup.find('section', class_='pr-review-snapshot-block-recommend')\n",
    "    if recommendation_section:\n",
    "        recommendation_percent = recommendation_section.find('span', class_='pr-reco-value').text.strip()\n",
    "        print(f\"Recommendation Percentage: {recommendation_percent}\")\n",
    "    else:\n",
    "        print(\"Recommendation section not found.\")\n",
    "\n",
    "    # Extracting reviews\n",
    "    reviews = soup.find_all('section', class_='pr-rd-content-block')\n",
    "    reviews_data = []\n",
    "\n",
    "    for idx, review in enumerate(reviews, start=1):\n",
    "        print(f\"\\nProcessing review {idx}:\")\n",
    "        \n",
    "        # Extracting review text\n",
    "        review_text = review.find('p', class_='pr-rd-description-text')\n",
    "        if review_text:\n",
    "            print(\"Review Text:\", review_text.text.strip())\n",
    "        else:\n",
    "            print(\"Review Text not found.\")\n",
    "        \n",
    "        # Adding review data\n",
    "        reviews_data.append({\n",
    "            'Star Rating': star_rating_label if star_rating else None,\n",
    "            'Rating Text': star_rating_text if star_rating_text else None,\n",
    "            'Review Text': review_text.text.strip() if review_text else None\n",
    "        })\n",
    "\n",
    "    return reviews_data\n",
    "\n",
    "\n",
    "# Selenium setup\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "def get_page_soup(url):\n",
    "    print(f\"Getting page soup for URL: {url}\")\n",
    "    driver.get(url)\n",
    "    time.sleep(1)  # Wait for the page to load\n",
    "    html = driver.page_source\n",
    "    return BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "def search_product(product_id):\n",
    "    print(f\"Searching for product ID: {product_id}\")\n",
    "    search_url = f'https://www.zoro.com/search?q={product_id}'\n",
    "    soup = get_page_soup(search_url)\n",
    "\n",
    "    # Find the specific product link using a precise CSS selector\n",
    "    for a in soup.select('a.product-card-image__link'):\n",
    "        print(f\"Checking link: {a['href']}\")\n",
    "        if product_id.lower() in a['href'].lower():\n",
    "            product_url = urljoin(search_url, a['href'])\n",
    "            print(f\"Found product URL: {product_url}\")\n",
    "            return product_url\n",
    "\n",
    "    print(\"Product URL not found.\")\n",
    "    return None\n",
    "\n",
    "def find_reviews_link(product_url):\n",
    "    print(f\"Finding reviews link on product URL: {product_url}\")\n",
    "    soup = get_page_soup(product_url)\n",
    "\n",
    "    # Find the reviews link using a precise CSS selector\n",
    "    for a in soup.select('a'):\n",
    "        print(f\"Checking link: {a['href']}\")\n",
    "        if 'reviews' in a['href']:\n",
    "            reviews_url = urljoin(product_url, a['href'])\n",
    "            print(f\"Found reviews URL: {reviews_url}\")\n",
    "            return reviews_url\n",
    "\n",
    "    print(\"Reviews URL not found.\")\n",
    "    return None\n",
    "\n",
    "def navigate_to_reviews(product_id):\n",
    "    print(f\"Navigating to reviews for product ID: {product_id}\")\n",
    "    product_url = search_product(product_id)\n",
    "    if product_url:\n",
    "        reviews_url = find_reviews_link(product_url)\n",
    "        if reviews_url:\n",
    "            print(f\"Navigating to reviews URL: {reviews_url}\")\n",
    "            driver.get(reviews_url)\n",
    "            time.sleep(1)  # Wait for the reviews page to load\n",
    "            # Extract page source after page load\n",
    "            html_content = driver.page_source\n",
    "        \n",
    "            # Pass HTML content to extract_reviews function\n",
    "            reviews_data = extract_reviews(html_content)\n",
    "            \n",
    "            # Print extracted reviews data\n",
    "            print(\"\\nExtracted Reviews:\")\n",
    "            for review in reviews_data:\n",
    "                print(review)\n",
    "        else:\n",
    "            print(\"Reviews URL not found.\")\n",
    "    else:\n",
    "        print(\"Product URL not found.\")\n",
    "\n",
    "product_id = '1VCE8'\n",
    "navigate_to_reviews(product_id)\n",
    "\n",
    "driver.quit()\n"
   ],
   "id": "47c96d4b1c533ca6",
   "execution_count": 41,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "7690dd191b271eac",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T01:29:58.878222Z",
     "start_time": "2024-06-24T01:29:58.875462Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1f4b28f423b7ec61",
   "execution_count": 9,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
