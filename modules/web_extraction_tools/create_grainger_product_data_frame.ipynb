{
 "cells": [
  {
   "cell_type": "code",
   "id": "2a11e5f910934738",
   "metadata": {},
   "source": [
    "import os\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "domain = \"https://www.grainger.com\"\n",
    "local_domain = urlparse(domain).netloc\n",
    "# Create necessary directories if they don't exist\n",
    "if not os.path.exists(\"text/\"):\n",
    "    os.mkdir(\"text/\")\n",
    "if not os.path.exists(f\"text/{local_domain}/\"):\n",
    "    os.mkdir(f\"text/{local_domain}/\")\n",
    "if not os.path.exists(\"processed\"):\n",
    "    os.mkdir(\"processed\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a61fd1fe2b624523",
   "metadata": {},
   "source": [
    "# TEST \n",
    "import re\n",
    "\n",
    "# Pattern to match product skus/codes\n",
    "regex_pattern = re.compile(r'[A-Z0-9]{5,7}')\n",
    "# Test strings\n",
    "test_strings = [\n",
    "    \"1DKW3_1.pdf\",\n",
    "    \"3VE59C-Operating-Instructions-and-Parts-Manual.pdf\",\n",
    "    \"_3M-Disposable-Respirator-Dual-4JF99?opr=PDPBRDSP&analytics=dsbrItems_5ZZZ6.txt\"\n",
    "]\n",
    "\n",
    "# Extract product codes from test strings\n",
    "for test in test_strings:\n",
    "    matches = regex_pattern.findall(test)\n",
    "    print(f\"Matches in '{test}': {matches}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # PULL product codes from web scraped data and save as json\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Define the regex pattern for product codes\n",
    "regex_pattern = re.compile(r'[A-Z0-9]{5,7}')\n",
    "\n",
    "# Directory containing the files\n",
    "directory = 'text/www.grainger.com'\n",
    "\n",
    "# Load existing product codes from the JSON file\n",
    "existing_product_codes = []\n",
    "print(\"os.path.exists('all_product_codes.json')\", os.path.exists('all_product_codes.json'))\n",
    "if os.path.exists('all_product_codes.json'):\n",
    "    with open('all_product_codes.json', 'r') as f:\n",
    "        existing_product_codes = json.load(f)\n",
    "\n",
    "# List to store found product codes\n",
    "product_codes = []\n",
    "\n",
    "# Function to extract product codes from text\n",
    "def extract_product_codes(text):\n",
    "    return regex_pattern.findall(text)\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "\n",
    "        # Check for product codes in the file name\n",
    "        print(f\"reading: {file_path}\")\n",
    "        codes_in_filename = extract_product_codes(file)\n",
    "        product_codes.extend(codes_in_filename)\n",
    "\n",
    "        # Check for product codes in the file content\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                codes_in_content = extract_product_codes(content)\n",
    "                product_codes.extend(codes_in_content)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read file {file_path}: {e}\")\n",
    "\n",
    "# Remove duplicates by converting the list to a set and back to a list\n",
    "product_codes = list(set(product_codes))\n",
    "\n",
    "# Combine existing and new product codes\n",
    "product_codes = list(set(existing_product_codes + product_codes))\n",
    "\n",
    "# Save all product codes to the JSON file\n",
    "with open('all_product_codes.json', 'w') as f:\n",
    "    json.dump(product_codes, f, indent=4)\n",
    "\n",
    "print(f\"Total product codes found: {len(product_codes)}\")\n",
    "print(f\"Product codes saved in 'all_product_codes.json'\")"
   ],
   "id": "e75e472252e9edd8",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f46f5676aa9f97a6",
   "metadata": {},
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import html\n",
    "import re\n",
    "\n",
    "# Base URL and headers for the API\n",
    "base_url = \"https://mobile-rest-qa.nonprod.graingercloud.com/v1/product/detail\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Function to fetch and process data\n",
    "def fetch_product_details(skus):\n",
    "    params = {\n",
    "        \"partNumbers\": skus,\n",
    "        \"extraInfo\": \"false\"\n",
    "    }\n",
    "    print(f\"Fetching details for SKUs: {skus}\")  # Debugging print statement\n",
    "    response = requests.get(base_url, headers=headers, params=params, verify=False)\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            data = response.json()\n",
    "            results = []\n",
    "            for item in data:\n",
    "                brand = item.get(\"brand\", {}).get(\"name\", \"N/A\")\n",
    "                code = item.get(\"code\", \"N/A\")\n",
    "                name = item.get(\"name\", \"N/A\")\n",
    "                picture_url = item.get(\"pictureUrl600\", \"N/A\")\n",
    "                price = item.get(\"priceData\", {}).get(\"formattedPrice\", \"N/A\")\n",
    "                description = item.get(\"productDetailsDescription\", \"N/A\")\n",
    "\n",
    "                results.append({\n",
    "                    \"Brand\": brand,\n",
    "                    \"Code\": code,\n",
    "                    \"Name\": name,\n",
    "                    \"PictureUrl600\": picture_url,\n",
    "                    \"Price\": price,\n",
    "                    \"Description\": description\n",
    "                })\n",
    "\n",
    "            print(f\"Successfully processed {len(results)} items.\")  # Debugging print statement\n",
    "            return pd.DataFrame(results) if results else None\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing response for {skus}: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Failed to fetch details for {skus}: Status code {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Load the product codes from the JSON file\n",
    "try:\n",
    "    with open('processed/all_product_codes.json', 'r') as f:\n",
    "        product_codes = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"JSON file 'all_product_codes.json' not found.\")\n",
    "else:\n",
    "    print(f\"Total product codes found: {len(product_codes)}\")\n",
    "\n",
    "# Product codes in chunks of 100\n",
    "chunk_size = 1 # Using 1 to prevent errors with invalid product codes preventing the rest from loading.\n",
    "chunks = [product_codes[i:i + chunk_size] for i in range(0, len(product_codes), chunk_size)]\n",
    "\n",
    "# Initialize DataFrame\n",
    "df = pd.DataFrame(columns=[\"Brand\", \"Code\", \"Name\", \"PictureUrl600\", \"Price\", \"Description\"])\n",
    "\n",
    "# Load existing data if the file exists\n",
    "parquet_path = 'processed/grainger_products.parquet'\n",
    "\n",
    "if os.path.exists(parquet_path):\n",
    "    df_existing = pd.read_parquet(parquet_path)\n",
    "    df = pd.concat([df, df_existing], ignore_index=True)\n",
    "    print(\"Loaded existing data from 'modules/vector_index/processed/grainger_products.parquet'.\")\n",
    "\n",
    "# Fetch and append new data\n",
    "failed_chunks = []\n",
    "for chunk in chunks:\n",
    "    try:\n",
    "        details = fetch_product_details(chunk)\n",
    "        if details is not None:\n",
    "            df = pd.concat([df, details], ignore_index=True)\n",
    "            print(f\"Successfully appended {len(details)} rows to DataFrame.\")  # Debugging print statement\n",
    "        else:\n",
    "            print(f\"No details fetched for chunk: {chunk}. Removing from source.\")\n",
    "            failed_chunks.extend(chunk)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch details for chunk: {chunk}, Error: {e}\")\n",
    "        failed_chunks.extend(chunk)\n",
    "\n",
    "# Ensure all column names are strings\n",
    "df.columns = df.columns.astype(str)\n",
    "\n",
    "# Complete data cleaning\n",
    "df.fillna(\"\", inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "def clean_code(code):\n",
    "    # Extract the part before any space or other characters\n",
    "    return re.split(r'\\s|[-_()]+', code, 1)[0]\n",
    "\n",
    "df['Code'] = df['Code'].apply(clean_code)\n",
    "# Remove HTML characters from all columns\n",
    "df = df.applymap(lambda x: html.unescape(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Save to Parquet\n",
    "parquet_path = 'processed/grainger_products.parquet'\n",
    "os.makedirs('processed', exist_ok=True)\n",
    "df.to_parquet(parquet_path, index=False)\n",
    "print(f\"Product details have been saved to {parquet_path}\")\n",
    "print(\"\\nHead of DataFrame:\")\n",
    "print(df.head(), \"\\n\")\n",
    "print(\"Tail of DataFrame:\")\n",
    "print(df.tail(), \"\\n\") \n",
    "print(\"Size of DataFrame:\", df.size, \"\\n\")\n",
    "print(\"Values in DataFrame:\")\n",
    "print(df.values)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "dd5ba3cf1b4ba2c9",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d0931a03f4e24a89",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Save to Parquet\n",
    "parquet_path = 'processed/grainger_products.parquet'\n",
    "os.makedirs('processed', exist_ok=True)\n",
    "df.to_parquet(parquet_path, index=False)\n",
    "print(f\"Product details have been saved to {parquet_path}\")\n",
    "print(\"\\nHead of DataFrame:\")\n",
    "print(df.head(), \"\\n\")\n",
    "print(\"Tail of DataFrame:\")\n",
    "print(df.tail(), \"\\n\") \n",
    "print(\"Size of DataFrame:\", df.size, \"\\n\")\n",
    "print(\"Values in DataFrame:\")\n",
    "print(df.values)"
   ],
   "id": "53af168ff9dd5472",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Complete data cleaning\n",
    "df.fillna(\"\", inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "def clean_code(code):\n",
    "    # Extract the part before any space (if exists)\n",
    "    return re.split(r'\\s+', code, 1)[0]\n",
    "\n",
    "df['Code'] = df['Code'].apply(clean_code)\n",
    "# Remove HTML characters from all columns\n",
    "df = df.applymap(lambda x: html.unescape(x) if isinstance(x, str) else x)\n",
    "\n"
   ],
   "id": "f48e8b68c8c91b6a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Save to Parquet\n",
    "os.makedirs('processed', exist_ok=True)\n",
    "df.to_parquet('processed/grainger_products.parquet', index=False)\n",
    "print(\"Product details have been saved to 'processed/grainger_products.parquet'\")\n",
    "print(\"\\nHead of DataFrame:\")\n",
    "print(df.head(), \"\\n\")\n",
    "print(\"Tail of DataFrame:\")\n",
    "print(df.tail(), \"\\n\")\n",
    "print(\"Size of DataFrame:\", df.size, \"\\n\")\n",
    "print(\"Values in DataFrame:\")\n",
    "print(df.values)\n"
   ],
   "id": "83da416308130c5f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T21:13:58.717175Z",
     "start_time": "2024-07-15T21:13:57.139349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('processed/grainger_products.parquet')\n",
    "df.head()"
   ],
   "id": "3f2c7abf94c1cf0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Brand    Code                                               Name  \\\n",
       "0            OHAUS   3JKR7  OHAUS Hanging Scale: 5000g/50 N, g, 100g/1 N, ...   \n",
       "1  GEORGIA-PACIFIC   3EB49  GEORGIA-PACIFIC Paper Towel Dispenser: Hardwou...   \n",
       "2        TOUGH GUY   5PHW9  TOUGH GUY Compostable Trash Bags: 33 gal Capac...   \n",
       "3          PELICAN  14L589  PELICAN Safety-Rated Flashlight: 183 lm Max. B...   \n",
       "4        TOUGH GUY   4KN29  TOUGH GUY Trash Bags: 24 in Wd, 33 in Ht, 6 mi...   \n",
       "\n",
       "                                       PictureUrl600    Price  \\\n",
       "0  https://static.grainger.com/rp/s/is/image/Grai...   $17.38   \n",
       "1  https://static.grainger.com/rp/s/is/image/Grai...   $69.73   \n",
       "2  https://static.grainger.com/rp/s/is/image/Grai...  $212.17   \n",
       "3  https://static.grainger.com/rp/s/is/image/Grai...   $64.20   \n",
       "4  https://static.grainger.com/rp/s/is/image/Grai...   $64.29   \n",
       "\n",
       "                                         Description  \n",
       "0  <p>Mechanical Hanging Scales include analog di...  \n",
       "1  <p>Motion-activated paper towel dispensers off...  \n",
       "2  <p>Compostable trash bags collect compostable ...  \n",
       "3  <p>These safety-rated flashlights set their he...  \n",
       "4  <p>Trash bags for soft refuse are made of HDPE...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Code</th>\n",
       "      <th>Name</th>\n",
       "      <th>PictureUrl600</th>\n",
       "      <th>Price</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OHAUS</td>\n",
       "      <td>3JKR7</td>\n",
       "      <td>OHAUS Hanging Scale: 5000g/50 N, g, 100g/1 N, ...</td>\n",
       "      <td>https://static.grainger.com/rp/s/is/image/Grai...</td>\n",
       "      <td>$17.38</td>\n",
       "      <td>&lt;p&gt;Mechanical Hanging Scales include analog di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GEORGIA-PACIFIC</td>\n",
       "      <td>3EB49</td>\n",
       "      <td>GEORGIA-PACIFIC Paper Towel Dispenser: Hardwou...</td>\n",
       "      <td>https://static.grainger.com/rp/s/is/image/Grai...</td>\n",
       "      <td>$69.73</td>\n",
       "      <td>&lt;p&gt;Motion-activated paper towel dispensers off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOUGH GUY</td>\n",
       "      <td>5PHW9</td>\n",
       "      <td>TOUGH GUY Compostable Trash Bags: 33 gal Capac...</td>\n",
       "      <td>https://static.grainger.com/rp/s/is/image/Grai...</td>\n",
       "      <td>$212.17</td>\n",
       "      <td>&lt;p&gt;Compostable trash bags collect compostable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PELICAN</td>\n",
       "      <td>14L589</td>\n",
       "      <td>PELICAN Safety-Rated Flashlight: 183 lm Max. B...</td>\n",
       "      <td>https://static.grainger.com/rp/s/is/image/Grai...</td>\n",
       "      <td>$64.20</td>\n",
       "      <td>&lt;p&gt;These safety-rated flashlights set their he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOUGH GUY</td>\n",
       "      <td>4KN29</td>\n",
       "      <td>TOUGH GUY Trash Bags: 24 in Wd, 33 in Ht, 6 mi...</td>\n",
       "      <td>https://static.grainger.com/rp/s/is/image/Grai...</td>\n",
       "      <td>$64.29</td>\n",
       "      <td>&lt;p&gt;Trash bags for soft refuse are made of HDPE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b757b066b09e5413"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
