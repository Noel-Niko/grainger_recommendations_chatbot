{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T05:14:31.692609Z",
     "start_time": "2024-06-24T05:14:19.332056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import os\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from collections import deque\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Setup Selenium WebDriver\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Base URL and domain to crawl\n",
    "domain = \"www.grainger.com\"\n",
    "start_url = \"https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?categoryIndex=6\"\n",
    "\n",
    "# Function to fetch HTML content from a URL using Selenium if needed\n",
    "def fetch_html(url):\n",
    "    try:\n",
    "        print(f\"Fetching URL: {url}\")\n",
    "        driver.get(url)\n",
    "        # Wait for up to 10 seconds for the category list to appear\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'div.JnMlkm.NmndfD'))\n",
    "        )\n",
    "        html = driver.page_source\n",
    "        if html:\n",
    "            print(f\"Fetched HTML from {url}\")\n",
    "            return html\n",
    "        else:\n",
    "            print(f\"Page source is empty for {url}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching URL {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract categories from HTML content\n",
    "def extract_categories(html_content):\n",
    "    categories = []\n",
    "    if html_content:\n",
    "        print(\"Extracting categories...\")\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        div = soup.find('div', class_='JnMlkm NmndfD')\n",
    "        if div:\n",
    "            print(\"Found category list.\")\n",
    "            for li in div.find_all('li', class_='KmpkFF'):\n",
    "                category = {}\n",
    "                a = li.find('a', class_='HJvUEo')\n",
    "                if a:\n",
    "                    category['title'] = a.text.strip()\n",
    "                    category['url'] = urljoin(start_url, a['href'])\n",
    "                    categories.append(category)\n",
    "                    print(f\"Added category: {category['title']}\")\n",
    "                else:\n",
    "                    print(\"Anchor tag not found for category.\")\n",
    "        else:\n",
    "            print(\"Could not find the category list.\")\n",
    "    return categories\n",
    "\n",
    "# Function to crawl starting from a URL\n",
    "def crawl(url):\n",
    "    print(f\"Starting crawl from URL: {url}\")\n",
    "    html_content = fetch_html(url)\n",
    "    if html_content:\n",
    "        categories = extract_categories(html_content)\n",
    "        for category in categories:\n",
    "            print(f\"Category: {category['title']}\")\n",
    "            print(f\"Category URL: {category['url']}\")\n",
    "\n",
    "# Start crawling from the base URL\n",
    "crawl(start_url)\n",
    "\n",
    "# Quit the Selenium driver\n",
    "driver.quit()\n"
   ],
   "id": "a9583ecb29c95bfe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting crawl from URL: https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?categoryIndex=6\n",
      "Fetching URL: https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?categoryIndex=6\n",
      "Error fetching URL https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?categoryIndex=6: Message: \n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000105bba088 chromedriver + 5169288\n",
      "1   chromedriver                        0x0000000105bb1f5a chromedriver + 5136218\n",
      "2   chromedriver                        0x000000010572e36c chromedriver + 402284\n",
      "3   chromedriver                        0x000000010577b740 chromedriver + 718656\n",
      "4   chromedriver                        0x000000010577ba01 chromedriver + 719361\n",
      "5   chromedriver                        0x00000001057c0bc4 chromedriver + 1002436\n",
      "6   chromedriver                        0x000000010579eadd chromedriver + 862941\n",
      "7   chromedriver                        0x00000001057bdf57 chromedriver + 991063\n",
      "8   chromedriver                        0x000000010579e853 chromedriver + 862291\n",
      "9   chromedriver                        0x000000010576e5c6 chromedriver + 665030\n",
      "10  chromedriver                        0x000000010576ee4e chromedriver + 667214\n",
      "11  chromedriver                        0x0000000105b7cca0 chromedriver + 4918432\n",
      "12  chromedriver                        0x0000000105b81c9d chromedriver + 4938909\n",
      "13  chromedriver                        0x0000000105b82375 chromedriver + 4940661\n",
      "14  chromedriver                        0x0000000105b5dd84 chromedriver + 4791684\n",
      "15  chromedriver                        0x0000000105b82669 chromedriver + 4941417\n",
      "16  chromedriver                        0x0000000105b4f554 chromedriver + 4732244\n",
      "17  chromedriver                        0x0000000105ba2838 chromedriver + 5072952\n",
      "18  chromedriver                        0x0000000105ba29f7 chromedriver + 5073399\n",
      "19  chromedriver                        0x0000000105bb1b0e chromedriver + 5135118\n",
      "20  libsystem_pthread.dylib             0x00007ff8057c9202 _pthread_start + 99\n",
      "21  libsystem_pthread.dylib             0x00007ff8057c4bab thread_start + 15\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T05:03:59.430431Z",
     "start_time": "2024-06-24T05:03:59.426780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_newlines(serie):\n",
    "    serie = serie.str.replace('\\n', ' ')\n",
    "    serie = serie.str.replace('\\\\n', ' ')\n",
    "    serie = serie.str.replace('  ', ' ')\n",
    "    serie = serie.str.replace('  ', ' ')\n",
    "    return serie"
   ],
   "id": "b3fb6b81affae7a6",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T04:43:17.375448Z",
     "start_time": "2024-06-24T04:43:14.347047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create a list to store the text files\n",
    "texts=[]\n",
    "\n",
    "domain_dir = os.path.join(\"text\", domain)\n",
    "abs_domain_dir = os.path.abspath(domain_dir)\n",
    "\n",
    "if os.path.exists(abs_domain_dir):\n",
    "    # Get all the text files in the text directory\n",
    "    for file in os.listdir(\"text/\" + domain + \"/\"):\n",
    "        \n",
    "        try:\n",
    "            # Open the file and read the text\n",
    "            with open(\"text/\" + domain + \"/\" + file, \"r\") as f:\n",
    "                text = f.read()\n",
    "        \n",
    "                # Omit the first 11 lines and the last 4 lines, then replace -, _, and #update with spaces.\n",
    "                texts.append((file[11:-4].replace('-',' ').replace('_', ' ').replace('#update',''), text))\n",
    "        except Exception as e:\n",
    "            print(f\"Exception occurred during reading file '{text}': {e}\")       \n",
    "else:\n",
    "    print(f\"Directory '{abs_domain_dir}' does not exist.\")\n",
    "# Create a dataframe from the list of texts\n",
    "df = pd.DataFrame(texts, columns = ['fname', 'text'])\n",
    "\n",
    "# Set the text column to be the raw text with the newlines removed\n",
    "df['text'] = df.fname + \". \" + remove_newlines(df.text)\n",
    "df.to_csv('processed/scraped.csv')\n",
    "df.head()"
   ],
   "id": "e8004993afbfada5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_x/sgylm_cs37zg8cfcxk6076bh0000gn/T/ipykernel_38427/2966875972.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  serie = serie.str.replace('\\\\n', ' ')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                               fname  \\\n",
       "0                                              r.com   \n",
       "1  r.com category furnishings appliances hospital...   \n",
       "\n",
       "                                                text  \n",
       "0                                            r.com.   \n",
       "1  r.com category furnishings appliances hospital...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r.com</td>\n",
       "      <td>r.com.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r.com category furnishings appliances hospital...</td>\n",
       "      <td>r.com category furnishings appliances hospital...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T04:49:01.146963Z",
     "start_time": "2024-06-24T04:48:58.932372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# Assuming your dataframe 'df' is already created and contains a 'text' column\n",
    "df = pd.DataFrame({\n",
    "    'text': [\"This is a sample text.\", \"Another example text.\", \"Yet another text sample.\"]\n",
    "})\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Calculate the number of tokens for each text\n",
    "df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
    "\n",
    "# Visualize the distribution of the number of tokens per row using a histogram\n",
    "df.n_tokens.hist()\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Tokens per Text')\n",
    "plt.show()\n"
   ],
   "id": "403ac5207c912cfa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a816fa3f16a54c25a0da4bfa79fd354b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d655f282dc04c37b4801678e5c43807"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8eabe46bc2424a34be1349eb0b956629"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c4942f57a1a41a59570219d7792184f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/python-web-crawler-2/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a81973a1995e4b19a337419bc0f40eed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T05:30:25.205286Z",
     "start_time": "2024-06-24T05:30:18.382169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import os\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from collections import deque\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Selenium setup\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Base URL to ensure crawling stays within this path\n",
    "BASE_URL = \"https://www.grainger.com\"\n",
    "START_URL = \"https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\"\n",
    "# Function to get the hyperlinks from a URL\n",
    "def get_hyperlinks(url):\n",
    "    print(f\"Getting hyperlinks for URL: {url}\")\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(1)  # Wait for the page to load\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        hyperlinks = [a['href'] for a in soup.find_all('a', href=True)]\n",
    "        return hyperlinks\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting hyperlinks: {e}\")\n",
    "        return []\n",
    "\n",
    "# Function to get the hyperlinks from a URL that are within the same domain and base URL\n",
    "def get_domain_hyperlinks(local_domain, url):\n",
    "    clean_links = []\n",
    "    hyperlinks = get_hyperlinks(url)\n",
    "    print(f\"Found {len(hyperlinks)} hyperlinks on {url}\")\n",
    "    for link in set(hyperlinks):\n",
    "        clean_link = None\n",
    "        print(f\"Checking link: {link}\")\n",
    "        \n",
    "        # Handle absolute URLs\n",
    "        if re.search(r'^https?://', link):\n",
    "            url_obj = urlparse(link)\n",
    "            if url_obj.netloc == local_domain and link.startswith(BASE_URL):\n",
    "                clean_link = link\n",
    "        else:\n",
    "            # Handle relative URLs\n",
    "            clean_link = urljoin(url, link)\n",
    "            # if not clean_link.startswith(BASE_URL):\n",
    "            #     clean_link = None\n",
    "\n",
    "        if clean_link is not None:\n",
    "            print(f\"Adding clean link: {clean_link}\")\n",
    "            if clean_link.endswith(\"/\"):\n",
    "                clean_link = clean_link[:-1]\n",
    "            clean_links.append(clean_link)\n",
    "\n",
    "    print(f\"Clean links: {clean_links}\")\n",
    "    return list(set(clean_links))\n",
    "\n",
    "# Function to crawl the website\n",
    "def crawl(url):\n",
    "    local_domain = urlparse(BASE_URL).netloc  # Extract domain name from BASE_URL\n",
    "    queue = deque([url])\n",
    "    seen = {url}\n",
    "\n",
    "    # Create necessary directories if they don't exist\n",
    "    if not os.path.exists(\"text/\"):\n",
    "        os.mkdir(\"text/\")\n",
    "    if not os.path.exists(f\"text/{local_domain}/\"):\n",
    "        os.mkdir(f\"text/{local_domain}/\")\n",
    "    if not os.path.exists(\"processed\"):\n",
    "        os.mkdir(\"processed\")\n",
    "\n",
    "    while queue:\n",
    "        url = queue.pop()\n",
    "        print(f\"Crawling URL: {url}\")  # For debugging and to see the progress\n",
    "        try:\n",
    "            # Construct file path for saving content\n",
    "            file_path = f\"text/{local_domain}/{url[8:].replace('/', '_')}.txt\"\n",
    "            with open(file_path, \"w\") as f:\n",
    "                driver.get(url)\n",
    "                time.sleep(1)\n",
    "                soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                text = soup.get_text()\n",
    "                if \"You need to enable JavaScript to run this app.\" in text:\n",
    "                    print(f\"Unable to parse page {url} due to JavaScript being required\")\n",
    "                f.write(text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error crawling URL: {e}\")\n",
    "\n",
    "        try:\n",
    "            for link in get_domain_hyperlinks(local_domain, url):\n",
    "                if link not in seen:\n",
    "                    queue.append(link)\n",
    "                    seen.add(link)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing links: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Start crawling from the base URL\n",
    "crawl(START_URL)\n",
    "\n",
    "driver.quit()\n"
   ],
   "id": "e439e572d03f6d47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling URL: https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\n",
      "Getting hyperlinks for URL: https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\n",
      "Found 1 hyperlinks on https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\n",
      "Checking link: /\n",
      "Adding clean link: https://www.grainger.com/\n",
      "Clean links: ['https://www.grainger.com']\n",
      "Crawling URL: https://www.grainger.com\n",
      "Getting hyperlinks for URL: https://www.grainger.com\n",
      "Found 1 hyperlinks on https://www.grainger.com\n",
      "Checking link: /\n",
      "Adding clean link: https://www.grainger.com/\n",
      "Clean links: ['https://www.grainger.com']\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T05:23:15.761664Z",
     "start_time": "2024-06-24T05:22:21.440690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Sample HTML content (trimmed for brevity)\n",
    "html_content = \"\"\"\n",
    "<div class=\"zdGQVt\">\n",
    "   <aside id=\"filter-sidebar\" class=\"Hnd2sz\">\n",
    "      <h2 class=\"BdV2B\">Filters</h2>\n",
    "   </aside>\n",
    "   <div class=\"_3aIckp IBQ-S\">\n",
    "      <div id=\"category-container\">\n",
    "         <section data-testid=\"category-info\">\n",
    "            <p class=\"Gb4id\">Dog Park Equipment</p>\n",
    "         </section>\n",
    "         <section data-testid=\"category-carousel\">\n",
    "            <ul data-testid=\"category-header-slides\">\n",
    "               <li>\n",
    "                  <a href=\"https://www.grainger.com/product/ULTRAPLAY-Dog-Park-Kit-Doggie-Crawl-817KF7\">ULTRAPLAY Dog Park Kit: Doggie Crawl/Hoop Jump/Paws Table/Rover Jump Over</a>\n",
    "               </li>\n",
    "               <li>\n",
    "                  <a href=\"https://www.grainger.com/product/ULTRAPLAY-Dog-Park-Kit-Doggie-Crawl-817KF8\">Another Product</a>\n",
    "               </li>\n",
    "               <!-- Additional <li> elements for other products -->\n",
    "            </ul>\n",
    "         </section>\n",
    "      </div>\n",
    "      <div id=\"collection-164355\">\n",
    "         <ul class=\"fLkZ0b\">\n",
    "            <li>\n",
    "               <a href=\"https://www.grainger.com/product/ULTRAPLAY-Dog-Park-Kit-Doggie-Crawl-817KF7\">ULTRAPLAY Dog Park Kit: Doggie Crawl/Hoop Jump/Paws Table/Rover Jump Over</a>\n",
    "            </li>\n",
    "            <!-- Additional <li> elements for products in this collection -->\n",
    "         </ul>\n",
    "      </div>\n",
    "   </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "def extract_links(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    links = []\n",
    "\n",
    "    # Extract links from category-carousel section\n",
    "    category_carousel = soup.find('section', {'data-testid': 'category-carousel'})\n",
    "    if category_carousel:\n",
    "        for li in category_carousel.find_all('li'):\n",
    "            link = li.find('a')\n",
    "            if link and link.has_attr('href'):\n",
    "                links.append(link['href'])\n",
    "\n",
    "    # Extract links from collection-164355 section\n",
    "    collection_section = soup.find('div', {'id': 'collection-164355'})\n",
    "    if collection_section:\n",
    "        for li in collection_section.find_all('li'):\n",
    "            link = li.find('a')\n",
    "            if link and link.has_attr('href'):\n",
    "                links.append(link['href'])\n",
    "\n",
    "    return links\n",
    "\n",
    "# Function to check links\n",
    "def check_links(links):\n",
    "    results = {}\n",
    "    for link in links:\n",
    "        try:\n",
    "            response = requests.head(link, allow_redirects=True)\n",
    "            results[link] = response.status_code\n",
    "        except requests.RequestException as e:\n",
    "            results[link] = str(e)\n",
    "    return results\n",
    "\n",
    "# Extract links from HTML content\n",
    "extracted_links = extract_links(html_content)\n",
    "\n",
    "# Check status of extracted links\n",
    "link_status = check_links(extracted_links)\n",
    "\n",
    "# Print results\n",
    "for link, status in link_status.items():\n",
    "    print(f\"Link: {link}, Status Code: {status}\")\n"
   ],
   "id": "d7abfc2789bcb356",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link: https://www.grainger.com/product/ULTRAPLAY-Dog-Park-Kit-Doggie-Crawl-817KF7, Status Code: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Link: https://www.grainger.com/product/ULTRAPLAY-Dog-Park-Kit-Doggie-Crawl-817KF8, Status Code: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T05:32:20.871886Z",
     "start_time": "2024-06-24T05:32:14.431021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import os\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from collections import deque\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Selenium setup\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Base URL to ensure crawling stays within this path\n",
    "BASE_URL = \"https://www.grainger.com\"\n",
    "START_URL = \"https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\"\n",
    "\n",
    "# Function to get the hyperlinks from a URL\n",
    "def get_hyperlinks(url):\n",
    "    print(f\"Getting hyperlinks for URL: {url}\")\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(1)  # Wait for the page to load\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        hyperlinks = [a['href'] for a in soup.find_all('a', href=True)]\n",
    "        return hyperlinks\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting hyperlinks: {e}\")\n",
    "        return []\n",
    "\n",
    "# Function to get the hyperlinks from a URL that are within the same domain and base URL\n",
    "def get_domain_hyperlinks(local_domain, url):\n",
    "    clean_links = []\n",
    "    hyperlinks = get_hyperlinks(url)\n",
    "    print(f\"Found {len(hyperlinks)} hyperlinks on {url}\")\n",
    "    for link in set(hyperlinks):\n",
    "        clean_link = None\n",
    "        print(f\"Checking link: {link}\")\n",
    "        \n",
    "        # Handle absolute URLs\n",
    "        if re.search(r'^https?://', link):\n",
    "            url_obj = urlparse(link)\n",
    "            if url_obj.netloc == local_domain and link.startswith(BASE_URL):\n",
    "                clean_link = link\n",
    "        else:\n",
    "            # Handle relative URLs\n",
    "            clean_link = urljoin(url, link)\n",
    "\n",
    "        if clean_link is not None and clean_link not in clean_links:\n",
    "            print(f\"Adding clean link: {clean_link}\")\n",
    "            if clean_link.endswith(\"/\"):\n",
    "                clean_link = clean_link[:-1]\n",
    "            clean_links.append(clean_link)\n",
    "\n",
    "    print(f\"Clean links: {clean_links}\")\n",
    "    return list(set(clean_links))\n",
    "\n",
    "# Function to crawl the website\n",
    "def crawl(url):\n",
    "    local_domain = urlparse(BASE_URL).netloc\n",
    "    queue = deque([url])\n",
    "    seen = {url}\n",
    "\n",
    "    # Create necessary directories if they don't exist\n",
    "    if not os.path.exists(\"text/\"):\n",
    "        os.mkdir(\"text/\")\n",
    "    if not os.path.exists(f\"text/{local_domain}/\"):\n",
    "        os.mkdir(f\"text/{local_domain}/\")\n",
    "    if not os.path.exists(\"processed\"):\n",
    "        os.mkdir(\"processed\")\n",
    "\n",
    "    while queue:\n",
    "        url = queue.popleft()  # Use popleft to ensure we process URLs in a breadth-first manner\n",
    "        print(f\"Crawling URL: {url}\")\n",
    "        try:\n",
    "            # Construct file path for saving content\n",
    "            file_path = f\"text/{local_domain}/{url[8:].replace('/', '_')}.txt\"\n",
    "            with open(file_path, \"w\") as f:\n",
    "                driver.get(url)\n",
    "                time.sleep(1)\n",
    "                soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                text = soup.get_text()\n",
    "                if \"You need to enable JavaScript to run this app.\" in text:\n",
    "                    print(f\"Unable to parse page {url} due to JavaScript being required\")\n",
    "                f.write(text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error crawling URL: {e}\")\n",
    "\n",
    "        try:\n",
    "            for link in get_domain_hyperlinks(local_domain, url):\n",
    "                if link not in seen:\n",
    "                    queue.append(link)\n",
    "                    seen.add(link)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing links: {e}\")\n",
    "\n",
    "# Start crawling from the base URL\n",
    "crawl(START_URL)\n",
    "\n",
    "driver.quit()\n"
   ],
   "id": "891c4aa0f82252a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling URL: https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\n",
      "Getting hyperlinks for URL: https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\n",
      "Found 1 hyperlinks on https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\n",
      "Checking link: /\n",
      "Adding clean link: https://www.grainger.com/\n",
      "Clean links: ['https://www.grainger.com']\n",
      "Crawling URL: https://www.grainger.com\n",
      "Getting hyperlinks for URL: https://www.grainger.com\n",
      "Found 1 hyperlinks on https://www.grainger.com\n",
      "Checking link: /\n",
      "Adding clean link: https://www.grainger.com/\n",
      "Clean links: ['https://www.grainger.com']\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T05:50:59.082974Z",
     "start_time": "2024-06-24T05:50:44.418509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import os\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from collections import deque\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Selenium setup\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Base URL to ensure crawling stays within this path\n",
    "BASE_URL = \"https://www.grainger.com\"\n",
    "START_URL = \"https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\"\n",
    "\n",
    "# Function to get the hyperlinks from a URL using Selenium\n",
    "def get_hyperlinks(url):\n",
    "    print(f\"Getting hyperlinks for URL: {url}\")\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(3)  # Adjust wait time as needed based on page load speed\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        hyperlinks = [a['href'] for a in soup.find_all('a', href=True)]\n",
    "        return hyperlinks\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting hyperlinks: {e}\")\n",
    "        return []\n",
    "\n",
    "# Function to get the hyperlinks from a URL that are within the same domain and base URL\n",
    "def get_domain_hyperlinks(local_domain, url):\n",
    "    clean_links = []\n",
    "    hyperlinks = get_hyperlinks(url)\n",
    "    print(f\"Found {len(hyperlinks)} hyperlinks on {url}\")\n",
    "    for link in set(hyperlinks):\n",
    "        clean_link = None\n",
    "        print(f\"Checking link: {link}\")\n",
    "        \n",
    "        # Handle absolute URLs\n",
    "        if link.startswith(\"http\"):\n",
    "            url_obj = urlparse(link)\n",
    "            if url_obj.netloc == local_domain and link.startswith(BASE_URL):\n",
    "                clean_link = link\n",
    "        else:\n",
    "            # Handle relative URLs\n",
    "            clean_link = urljoin(url, link)\n",
    "\n",
    "        if clean_link is not None and clean_link not in clean_links:\n",
    "            print(f\"Adding clean link: {clean_link}\")\n",
    "            if clean_link.endswith(\"/\"):\n",
    "                clean_link = clean_link[:-1]\n",
    "            clean_links.append(clean_link)\n",
    "\n",
    "    print(f\"Clean links: {clean_links}\")\n",
    "    return list(set(clean_links))\n",
    "\n",
    "# Function to crawl the website\n",
    "def crawl(url):\n",
    "    local_domain = urlparse(BASE_URL).netloc\n",
    "    queue = deque([url])\n",
    "    seen = {url}\n",
    "\n",
    "    # Create necessary directories if they don't exist\n",
    "    if not os.path.exists(\"text/\"):\n",
    "        os.mkdir(\"text/\")\n",
    "    if not os.path.exists(f\"text/{local_domain}/\"):\n",
    "        os.mkdir(f\"text/{local_domain}/\")\n",
    "    if not os.path.exists(\"processed\"):\n",
    "        os.mkdir(\"processed\")\n",
    "\n",
    "    while queue:\n",
    "        url = queue.popleft()  # Use popleft to ensure we process URLs in a breadth-first manner\n",
    "        print(f\"Crawling URL: {url}\")\n",
    "        try:\n",
    "            # Construct file path for saving content\n",
    "            file_path = f\"text/{local_domain}/{url[8:].replace('/', '_')}.txt\"\n",
    "            with open(file_path, \"w\") as f:\n",
    "                driver.get(url)\n",
    "                time.sleep(3)  # Adjust wait time as needed based on page load speed\n",
    "                soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                text = soup.get_text()\n",
    "                if \"You need to enable JavaScript to run this app.\" in text:\n",
    "                    print(f\"Unable to parse page {url} due to JavaScript being required\")\n",
    "                f.write(text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error crawling URL: {e}\")\n",
    "\n",
    "        try:\n",
    "            for link in get_domain_hyperlinks(local_domain, url):\n",
    "                if link not in seen:\n",
    "                    queue.append(link)\n",
    "                    seen.add(link)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing links: {e}\")\n",
    "\n",
    "# Start crawling from the base URL\n",
    "crawl(START_URL)\n",
    "\n",
    "driver.quit()\n",
    "\n"
   ],
   "id": "ab162831b8633588",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling URL: https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\n",
      "Getting hyperlinks for URL: https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\n",
      "Found 1 hyperlinks on https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\n",
      "Checking link: /\n",
      "Adding clean link: https://www.grainger.com/\n",
      "Clean links: ['https://www.grainger.com']\n",
      "Crawling URL: https://www.grainger.com\n",
      "Getting hyperlinks for URL: https://www.grainger.com\n",
      "Found 1 hyperlinks on https://www.grainger.com\n",
      "Checking link: /\n",
      "Adding clean link: https://www.grainger.com/\n",
      "Clean links: ['https://www.grainger.com']\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T05:53:33.273992Z",
     "start_time": "2024-06-24T05:53:18.862632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import os\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from collections import deque\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Selenium setup\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Base URL to ensure crawling stays within this path\n",
    "BASE_URL = \"https://www.grainger.com\"\n",
    "START_URL = \"https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\"\n",
    "\n",
    "# Function to get the hyperlinks from a URL using Selenium\n",
    "def get_hyperlinks(url):\n",
    "    print(f\"Getting hyperlinks for URL: {url}\")\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(3)  # Adjust wait time as needed based on page load speed\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        hyperlinks = [a['href'] for a in soup.find_all('a', href=True)]\n",
    "        return hyperlinks\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting hyperlinks: {e}\")\n",
    "        return []\n",
    "\n",
    "# Function to get specific links using XPath\n",
    "def get_specific_links(xpath):\n",
    "    try:\n",
    "        elements = driver.find_elements_by_xpath(xpath)\n",
    "        links = [element.get_attribute('href') for element in elements]\n",
    "        return links\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting specific links: {e}\")\n",
    "        return []\n",
    "\n",
    "# Function to crawl the website\n",
    "def crawl(url):\n",
    "    local_domain = urlparse(BASE_URL).netloc\n",
    "    queue = deque([url])\n",
    "    seen = {url}\n",
    "\n",
    "    # Create necessary directories if they don't exist\n",
    "    if not os.path.exists(\"text/\"):\n",
    "        os.mkdir(\"text/\")\n",
    "    if not os.path.exists(f\"text/{local_domain}/\"):\n",
    "        os.mkdir(f\"text/{local_domain}/\")\n",
    "    if not os.path.exists(\"processed\"):\n",
    "        os.mkdir(\"processed\")\n",
    "\n",
    "    while queue:\n",
    "        url = queue.popleft()  # Use popleft to ensure we process URLs in a breadth-first manner\n",
    "        print(f\"Crawling URL: {url}\")\n",
    "        try:\n",
    "            # Construct file path for saving content\n",
    "            file_path = f\"text/{local_domain}/{url[8:].replace('/', '_')}.txt\"\n",
    "            with open(file_path, \"w\") as f:\n",
    "                driver.get(url)\n",
    "                time.sleep(3)  # Adjust wait time as needed based on page load speed\n",
    "                soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                text = soup.get_text()\n",
    "                if \"You need to enable JavaScript to run this app.\" in text:\n",
    "                    print(f\"Unable to parse page {url} due to JavaScript being required\")\n",
    "                f.write(text)\n",
    "                \n",
    "                # Example: Extracting specific links using XPath\n",
    "                specific_xpath = '//*[@id=\"collection-164356\"]/div[2]/div/ul/li/div/div/div[1]/div[1]/a'\n",
    "                specific_links = get_specific_links(specific_xpath)\n",
    "                print(f\"Specific links found: {specific_links}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error crawling URL: {e}\")\n",
    "\n",
    "        try:\n",
    "            for link in get_domain_hyperlinks(local_domain, url):\n",
    "                if link not in seen:\n",
    "                    queue.append(link)\n",
    "                    seen.add(link)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing links: {e}\")\n",
    "\n",
    "# Function to get the hyperlinks from a URL that are within the same domain and base URL\n",
    "def get_domain_hyperlinks(local_domain, url):\n",
    "    clean_links = []\n",
    "    hyperlinks = get_hyperlinks(url)\n",
    "    print(f\"Found {len(hyperlinks)} hyperlinks on {url}\")\n",
    "    for link in set(hyperlinks):\n",
    "        clean_link = None\n",
    "        print(f\"Checking link: {link}\")\n",
    "        \n",
    "        # Handle absolute URLs\n",
    "        if link.startswith(\"http\"):\n",
    "            url_obj = urlparse(link)\n",
    "            if url_obj.netloc == local_domain and link.startswith(BASE_URL):\n",
    "                clean_link = link\n",
    "        else:\n",
    "            # Handle relative URLs\n",
    "            clean_link = urljoin(url, link)\n",
    "\n",
    "        if clean_link is not None and clean_link not in clean_links:\n",
    "            print(f\"Adding clean link: {clean_link}\")\n",
    "            if clean_link.endswith(\"/\"):\n",
    "                clean_link = clean_link[:-1]\n",
    "            clean_links.append(clean_link)\n",
    "\n",
    "    print(f\"Clean links: {clean_links}\")\n",
    "    return list(set(clean_links))\n",
    "\n",
    "# Start crawling from the base URL\n",
    "crawl(START_URL)\n",
    "\n",
    "driver.quit()\n"
   ],
   "id": "8e4a4817eef2c0f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling URL: https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\n",
      "Error getting specific links: 'WebDriver' object has no attribute 'find_elements_by_xpath'\n",
      "Specific links found: []\n",
      "Getting hyperlinks for URL: https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\n",
      "Found 1 hyperlinks on https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\n",
      "Checking link: /\n",
      "Adding clean link: https://www.grainger.com/\n",
      "Clean links: ['https://www.grainger.com']\n",
      "Crawling URL: https://www.grainger.com\n",
      "Error getting specific links: 'WebDriver' object has no attribute 'find_elements_by_xpath'\n",
      "Specific links found: []\n",
      "Getting hyperlinks for URL: https://www.grainger.com\n",
      "Found 1 hyperlinks on https://www.grainger.com\n",
      "Checking link: /\n",
      "Adding clean link: https://www.grainger.com/\n",
      "Clean links: ['https://www.grainger.com']\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T05:56:11.156957Z",
     "start_time": "2024-06-24T05:56:09.606010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Selenium setup\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Base URL to ensure crawling stays within this path\n",
    "BASE_URL = \"https://www.grainger.com\"\n",
    "START_URL = \"https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\"\n",
    "\n",
    "# Function to get specific links using XPath\n",
    "def get_specific_links(xpath):\n",
    "    try:\n",
    "        elements = driver.find_elements_by_xpath(xpath)\n",
    "        links = [element.get_attribute('href') for element in elements]\n",
    "        return links\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting specific links: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example usage\n",
    "specific_xpath = '//*[@id=\"collection-164356\"]/div[2]/div/ul/li/div/div/div[1]/div[1]/a'\n",
    "specific_links = get_specific_links(specific_xpath)\n",
    "print(f\"Specific links found: {specific_links}\")\n",
    "\n",
    "driver.quit()\n"
   ],
   "id": "74f6a81dc0f72d5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting specific links: 'WebDriver' object has no attribute 'find_elements_by_xpath'\n",
      "Specific links found: []\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:01:37.094116Z",
     "start_time": "2024-06-24T06:01:22.529596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import os\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from collections import deque\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Check WebDriver version to ensure compatibility\n",
    "driver_version = driver.capabilities['browserVersion']\n",
    "print(f\"Selenium WebDriver Version: {driver_version}\")\n",
    "\n",
    "# Selenium setup\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Base URL to ensure crawling stays within this path\n",
    "BASE_URL = \"https://www.grainger.com\"\n",
    "START_URL = \"https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\"\n",
    "\n",
    "# Function to get the hyperlinks from a URL using Selenium\n",
    "def get_hyperlinks(url):\n",
    "    print(f\"Getting hyperlinks for URL: {url}\")\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(3)  # Adjust wait time as needed based on page load speed\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        hyperlinks = [a['href'] for a in soup.find_all('a', href=True)]\n",
    "        return hyperlinks\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting hyperlinks: {e}\")\n",
    "        return []\n",
    "\n",
    "# Function to get specific links using XPath\n",
    "def get_specific_links(xpath):\n",
    "    try:\n",
    "        elements = driver.find_elements_by_xpath(xpath)\n",
    "        links = [element.get_attribute('href') for element in elements]\n",
    "        return links\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting specific links: {e}\")\n",
    "        return []\n",
    "\n",
    "# Function to crawl the website\n",
    "def crawl(url):\n",
    "    local_domain = urlparse(BASE_URL).netloc\n",
    "    queue = deque([url])\n",
    "    seen = {url}\n",
    "\n",
    "    # Create necessary directories if they don't exist\n",
    "    if not os.path.exists(\"text/\"):\n",
    "        os.mkdir(\"text/\")\n",
    "    if not os.path.exists(f\"text/{local_domain}/\"):\n",
    "        os.mkdir(f\"text/{local_domain}/\")\n",
    "    if not os.path.exists(\"processed\"):\n",
    "        os.mkdir(\"processed\")\n",
    "\n",
    "    while queue:\n",
    "        url = queue.popleft()  # Use popleft to ensure we process URLs in a breadth-first manner\n",
    "        print(f\"Crawling URL: {url}\")\n",
    "        try:\n",
    "            # Construct file path for saving content\n",
    "            file_path = f\"text/{local_domain}/{url[8:].replace('/', '_')}.txt\"\n",
    "            with open(file_path, \"w\") as f:\n",
    "                driver.get(url)\n",
    "                time.sleep(3)  # Adjust wait time as needed based on page load speed\n",
    "                soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                text = soup.get_text()\n",
    "                if \"You need to enable JavaScript to run this app.\" in text:\n",
    "                    print(f\"Unable to parse page {url} due to JavaScript being required\")\n",
    "                f.write(text)\n",
    "                \n",
    "                # Example: Extracting specific links using XPath\n",
    "                specific_xpath = '//*[@id=\"collection-164356\"]/div[2]/div/ul/li/div/div/div[1]/div[1]/a'\n",
    "                specific_links = get_specific_links(specific_xpath)\n",
    "                print(f\"Specific links found: {specific_links}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error crawling URL: {e}\")\n",
    "\n",
    "        try:\n",
    "            for link in get_domain_hyperlinks(local_domain, url):\n",
    "                if link not in seen:\n",
    "                    queue.append(link)\n",
    "                    seen.add(link)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing links: {e}\")\n",
    "\n",
    "# Function to get the hyperlinks from a URL that are within the same domain and base URL\n",
    "def get_domain_hyperlinks(local_domain, url):\n",
    "    clean_links = []\n",
    "    hyperlinks = get_hyperlinks(url)\n",
    "    print(f\"Found {len(hyperlinks)} hyperlinks on {url}\")\n",
    "    for link in set(hyperlinks):\n",
    "        clean_link = None\n",
    "        print(f\"Checking link: {link}\")\n",
    "        \n",
    "        # Handle absolute URLs\n",
    "        if link.startswith(\"http\"):\n",
    "            url_obj = urlparse(link)\n",
    "            if url_obj.netloc == local_domain and link.startswith(BASE_URL):\n",
    "                clean_link = link\n",
    "        else:\n",
    "            # Handle relative URLs\n",
    "            clean_link = urljoin(url, link)\n",
    "\n",
    "        if clean_link is not None and clean_link not in clean_links:\n",
    "            print(f\"Adding clean link: {clean_link}\")\n",
    "            if clean_link.endswith(\"/\"):\n",
    "                clean_link = clean_link[:-1]\n",
    "            clean_links.append(clean_link)\n",
    "\n",
    "    print(f\"Clean links: {clean_links}\")\n",
    "    return list(set(clean_links))\n",
    "\n",
    "# Start crawling from the base URL\n",
    "crawl(START_URL)\n",
    "\n",
    "driver.quit()\n"
   ],
   "id": "1c432be7f70b4db4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selenium WebDriver Version: 126.0.6478.63\n",
      "Crawling URL: https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\n",
      "Error getting specific links: 'WebDriver' object has no attribute 'find_elements_by_xpath'\n",
      "Specific links found: []\n",
      "Getting hyperlinks for URL: https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\n",
      "Found 1 hyperlinks on https://www.grainger.com/category/furnishings-appliances-hospitality/fitness-sports-recreation/dog-park-equipment?filters=webParentSkuKey&webParentSkuKey=WP15398236\n",
      "Checking link: /\n",
      "Adding clean link: https://www.grainger.com/\n",
      "Clean links: ['https://www.grainger.com']\n",
      "Crawling URL: https://www.grainger.com\n",
      "Error getting specific links: 'WebDriver' object has no attribute 'find_elements_by_xpath'\n",
      "Specific links found: []\n",
      "Getting hyperlinks for URL: https://www.grainger.com\n",
      "Found 1 hyperlinks on https://www.grainger.com\n",
      "Checking link: /\n",
      "Adding clean link: https://www.grainger.com/\n",
      "Clean links: ['https://www.grainger.com']\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c90a548c527fb797"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
